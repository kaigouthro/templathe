# Callbacks

## ğŸ“„ï¸ Argilla

Argilla - Open-source data platform for LLMs

## ğŸ“„ï¸ Confident

DeepEval package for unit testing LLMs.

## ğŸ“„ï¸ Context

Context - User Analytics for LLM Powered Products

## ğŸ“„ï¸ Infino

This example shows how one can track the following while calling OpenAI and ChatOpenAI models via LangChain and Infino:

## ğŸ“„ï¸ Label Studio

Label Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.

## ğŸ“„ï¸ LLMonitor

LLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.

## ğŸ“„ï¸ PromptLayer

PromptLayer

## ğŸ“„ï¸ SageMaker Tracking

This notebook shows how LangChain Callback can be used to log and track prompts and other LLM hyperparameters into SageMaker Experiments. Here, we use different scenarios to showcase the capability:

## ğŸ“„ï¸ Streamlit

Streamlit is a faster way to build and share data apps.

## ğŸ“„ï¸ Trubrics

Trubrics
